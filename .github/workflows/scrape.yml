name: Daily Scrape

on:
  schedule:
    - cron: "30 3 * * *"   # 9:00 AM IST daily (IST = UTC+5:30)
  workflow_dispatch:        # lets you run it manually from the Actions tab

permissions:
  contents: write           # allow pushing updated JSON files

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    concurrency:
      group: tfbdmap-scrape
      cancel-in-progress: true

    env:
      PYTHONUNBUFFERED: "1"   # cleaner logs
      # Your scraper should read OPENAI_API_KEY from env
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0          # needed so we can push later
          persist-credentials: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Playwright is often required by ScrapeGraphAI for dynamic pages
      - name: Install Playwright browsers and system deps
        run: |
          python -m playwright install chromium
          python -m playwright install-deps

      - name: Run scraper
        run: |
          python scraper.py

      # Optional: show the files that changed (helps debug)
      - name: Show changes
        run: |
          echo "Changed files:"
          git status --porcelain || true

      # Commit and push only if something changed (e.g., data/events.json)
      - name: Commit and push updated data
        run: |
          set -e
          BRANCH="${{ github.ref_name }}"
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Stage only data files you expect to change
          git add data/*.json || true

          if git diff --cached --quiet; then
            echo "No data changes to commit."
            exit 0
          fi

          DATE_UTC=$(date -u +'%Y-%m-%d')
          git commit -m "chore: update scraped data ($DATE_UTC)"
          # Rebase to avoid push conflicts if branch moved
          git pull --rebase origin "$BRANCH" || true
          git push origin "$BRANCH"
