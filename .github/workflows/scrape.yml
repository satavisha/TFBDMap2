name: Daily TFBD Scrape

on:
  schedule:
    - cron: "30 3 * * *"   # 9:00 AM IST
  workflow_dispatch: {}
  push:
    paths:
      - ".github/workflows/scrape.yml"
      - "scraper.py"
      - "requirements.txt"
      - "websites_list.txt"

permissions:
  contents: write

concurrency:
  group: daily-scrape
  cancel-in-progress: true

jobs:
  scrape:
    runs-on: ubuntu-22.04
    timeout-minutes: 30
    env:
      TZ: Asia/Kolkata

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Upgrade pip
        run: python -m pip install --upgrade pip

      - name: Install Python dependencies
        run: pip install -r requirements.txt

      # üëá FIXED: use npx, not sudo python
      - name: Install Playwright Linux dependencies
        run: npx playwright install-deps

      - name: Install Playwright browsers
        run: python -m playwright install

      - name: Show environment (debug)
        run: |
          python --version
          pip freeze | sed -n '1,120p'

      - name: Run scraper
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: python scraper.py

      - name: Commit and push if data changed
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          if [ -n "$(git status --porcelain data)" ]; then
            git add data/*.json
            git commit -m "chore: update scraped data [skip ci]"
            git push
            echo "‚úÖ Pushed updated JSON."
          else
            echo "‚ÑπÔ∏è No data changes to commit."
          fi
